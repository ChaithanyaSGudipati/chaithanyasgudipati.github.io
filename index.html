<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Chaithanya S Gudipati</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css"/></noscript>
		<style>
			/* Popup container */
			body {
    font-family: 'Saira Semi Condensed', sans-serif;
  padding:30px;
}
.popup-link{
  display:flex;
  flex-wrap:wrap;
  text-decoration:none!important;
}
.noDecoration, a:link, a:visited {
    text-decoration: none;
}

.popup-link a{
    padding: auto;
    border-radius: auto;
    font-size:17px;
    cursor:pointer;
    margin:auto;
	border-bottom: none;
    text-decoration:none;
}

.popup-container {
    visibility: hidden;
    opacity: 0;
    transition: all 0.3s ease-in-out;
    transform: scale(1.3);
    position: fixed;
    z-index: 1;
    left: 0;
    top: 0;
    width: 100%;
    height: 100%;
    background-color: rgba(21, 17, 17, 0.61);
    display: flex;
    align-items: center;
}
.popup-content {
    background-color: #fefefe;
    margin: auto;
    padding: 20px;
    border: 1px solid #888;
    width: 50%;
}
.popup-content p{
	color:#333;
    font-size: 17px;
    padding: 10px;
    line-height: 20px;
}
.popup-content a.close{
    color: #aaaaaa;
    float: right;
    font-size: 28px;
    font-weight: bold;
    background: none;
    padding: 0;
    margin: 0;
    text-decoration:none;
}

.popup-content a.close:hover{
  color:#000;
}

.popup-content span:hover,
.popup-content span:focus {
    color: #000;
    text-decoration: none;
    cursor: pointer;
}

.popup-container:target{
  visibility: visible;
  opacity: 1;
  transform: scale(1);
}

.popup-container h3{
  margin:10px;
}
		.images {
            display: flex;
            flex-wrap: wrap;
            margin: 0 50px;
        }
  
        .photo {
            max-width: 31.333%;
            padding: 0 10px;
            height: 180px;
        }
  
        .photo img {
            width: 100%;
            height: 100%;
        }
		</style>
		
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<!-- <span class="logo"><img src="images/logo.svg" alt="" /></span> -->
						<h1>Chaithanya S Gudipati</h1>
						Senior Data Engineer | Building Scalable Data Pipelines & Analytics Platforms | 5+ YOE in ETL, SQL, Python, Cloud, Spark | Power BI & Tableau Expertise</br>
						<ul>
					
						 <a href="AWS Certified Developer Associate certificate" target="_blank" style="color: whitesmoke">AWS Developer Associate</a></br>
						 <a href="AWS_CloudPractitioner.pdf" target="_blank" style="color: whitesmoke">AWS Certified Cloud Practitioner</a>
					    </ul>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="#home" class="active">Home</a></li>
							<li><a href="#intro">About Me</a></li>
							<li><a href="#experience">Experience</a></li>
							<li><a href="#second">Skills</a></li>
							<li><a href="#projects">Projects</a></li>
							

						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Introduction -->
							<section id="intro" class="main">
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2>About Me!!</h2>
										</header>
										<p align="justify">I am a results-oriented Data Engineer with over 6 years of experience designing and implementing scalable data infrastructure and pipelines across industries including Healthcare, Finance, Pharmaceuticals, and B2B SaaS. I specialize in transforming complex, high-volume datasets into reliable, production-ready systems that power analytics, reporting, and AI/ML-driven applications. </br>
											</p>
										<p align="justify">I bring deep expertise in SQL, Python, R, and Scala, with a strong focus on building scalable data solutions using Apache Spark and PySpark for distributed processing of large-scale datasets. My experience spans architecting robust ETL and ELT pipelines across cloud platforms including AWS (S3, Glue, Lambda), Azure (Data Factory, Synapse), Google Cloud (BigQuery, Cloud Functions), Snowflake, and Redshift, ensuring high performance, data quality, and governance. I’ve worked extensively with Apache Kafka for real-time streaming, Apache Airflow for workflow orchestration, and dbt for modular, version-controlled data modeling. These solutions have powered production-grade analytics, machine learning pipelines, and business intelligence systems, enabling data-driven decision-making across fast-paced, data-intensive environments.</br>  
											</p>
										<p align="justify">In support of data science initiatives, I’ve collaborated closely with ML teams to build and deploy end-to-end AI/ML pipelines, covering data ingestion, feature engineering, model inference, monitoring, and retraining workflows. I’ve operationalized models for use cases such as credit risk scoring, customer segmentation, and sales forecasting, leveraging tools like Airflow, MLflow, and Docker to enable CI/CD and real-time scoring in production environments</br>  
											</p>
										<p align="justify">Beyond pipeline development, I’ve also supported real-time and batch processing using Apache Spark, Kafka, and streaming data frameworks, enabling faster analytics and decision-making for time-sensitive operations. My BI experience with Power BI, Tableau, and Looker allows me to bridge engineering and analytics, ensuring downstream stakeholders can act on clean, well-modeled data.Whether optimizing data pipelines for healthcare compliance, building real-time scoring infrastructure for financial risk models, or enabling self-serve analytics for marketing teams, I bring a strong mix of engineering discipline, business acumen, and a passion for deploying intelligent, scalable data solutions that drive measurable outcomes.</br>  
											</p>
										
										
										
									</div>
									<span class="image"><img src="images/profile-img1.jpg" alt="" /></span>
								</div>
							</section>
							<section id="experience" class="main">
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2>Experience</h2>
											<h3>Data Science Engineer, Globex Digital Corp </h3>
										</header>
										<h4><ol>
											<l align="justify">1. Built and deployed end-to-end data pipelines supporting AI/ML workflows, including data ingestion, transformation, and feature engineering stages, enabling real-time model retraining for credit risk scoring and fraud detection</l> </br>
											<l align="justify">2. Maintained production-grade data pipelines using Apache Airflow, ensuring reliability through automated retries, alerting, and logging and set up proactive monitoring to meet SLAs and reduce pipeline failures in critical financial applications </l> </br>
											<l align="justify">3. Monitored and maintained AI/ML data workflows post-deployment, implementing logging, data drift detection, and automated validation checks to ensure model performance consistency in production environments </l> </br>
											<l align="justify">4. Designed data transformation pipelines for insurance client, implementing efficient DB2 to Hadoop migration using Apache Sqoop and Apache Spark, ensuring data consistency and business continuity while managing complex data life cycles </l> </br>
											<l align="justify">5. Optimized ETL workflows by refining stored procedures, tuning parameters, and enhancing SQL query performance, resulting in a 25% reduction in execution time and integrated Spark jobs for distributed processing of large policyholder dataset </l> </br>
											<l align="justify">6. Engineered scalable batch jobs and RESTful microservices using Python and Java to support credit scoring, transaction validation, and policy management workflows across high-volume financial and insurance systems. Integrated APIs with third-party credit bureaus and internal risk engines, enabling near real-time credit assessments</l> </br>
											<l align="justify">7. Developed batch processing jobs to transform and aggregate daily transaction data into weekly and monthly analytical tables in DB2 warehouse supporting business reporting needs </l> </br>
											<l align="justify">8. Developed automated ingestion and transformation processes for claims and billing data in a healthcare setting, increasing reporting accuracy and compliance with payer requirements</l> </br>
											<l align="justify">9.Developed data models and NoSQL schema designs (MongoDB/DynamoDB) for unstructured cheque image data and real-time Kafka-based event ingestion pipelines, supporting flexible querying and scalable storage</l> </br>
											<l align="justify">10. Designed OLTP processes and optimized underlying relational database schemas (DB2, PostgreSQL) for daily banking transactions handling 500k+ transactions per day, ensuring efficient data capture and storage for real-time processing </l> </br>
											<l align="justify">11. Built secure data pipelines for image cheque processing in DB2, implementing ETL workflows with data privacy controls and data governance standards for transaction validation </l> </br>
											<l align="justify">12.Led production incidents with 2-hour SLA compliance, implementing proactive monitoring and automated recovery procedures, significantly reducing system downtime through effective root cause analysis and troubleshooting</l> 
										</ol>
										<header class="major">
											
											<h3>Data Science Analyst, Tata Elxsi</h3>
										</header>
										<h4><ol>
											<l align="justify">1. Architected fault-tolerant ETL pipelines processing 1 TB annual retail data from POS, e-commerce platforms, DB2, and SQL Server into RedShift using AWS Lambda for batch processing, and Glue for transformations </l> </br>
											<l align="justify">2. Orchestrated end-to-end data operations using Airflow and Infrastructure as code (IaC) with Terraform, ensuring consistent data delivery for analytics and real-time decision making </l> </br>
											<l align="justify">3. Developed automated data quality checks and schema evolution handling for credit application pipeline, enabling instant credit decisions through ML model retraining and optimizing data storage with Parquet format </l> </br>
											<l align="justify">4. Developed advanced SQL transformations and ad hoc reporting workflows across legacy (DB2, SQL Server) and modern (Redshift) databases, enabling business insights through self-serve dashboards built in Tableau and Looker</l> </br>
											<l align="justify">5. Automated mortgage data processing with Airflow and DBT pipeline, which resulted in accelerating loan approvals by 15%, enhancing customer satisfaction, and minimizing operational delays </l> </br>
											<l align="justify">6. Maintained a Python CDC pipeline that captured PostgreSQL WAL transactions, transformed into JSON format, and archived them into S3, then processed and loaded into Amazon RedShift for analytical purposes </l> </br>
											<l align="justify">7.Collaborated with Growth Marketing team to optimize $125M marketing budget by analyzing customer acquisition channels through data pipelines built with dbt, Airflow and RedShift </l> 
										</ol>
										<header class="major">
											<h3>Intern, Tata Elxsi</h3>
										</header>
										<h4><ol>
											<l align="justify">1. Developed a dynamic Tableau dashboard to analyze healthcare supply chain trends, manage inventory, and forecast stock levels, improving visibility into KPIs and increasing operational efficiency by 40% </l> </br>
											<l align="justify">2. Implemented data quality checks and cleansing processes within ETL pipelines, reducing data errors by 35% and ensuring high data accuracy, completeness and consistency </l>
										</ol>
										
										
										
									</div>
									
								</div>
							</section>

						<!-- First Section -->
							<section id="second" class="main special">
								<header class="major">
									<h2>Top Skills</h2>
									
								</header>
								
								<ul class="statistics">
									
									<li class="style1">
										<span class="icon solid fa-database"></span>
										<br/> 
										<div class="popup-link">
										<a href="#popup1">Data Management</br><strong>+</strong></a>
										<div id="popup1" class="popup-container">
										<div class="popup-content">
										<a href="#second" class="close">&times;</a>
										<h3>Data Management</h3>
										<h5>Tools: MySQL, MongoDB</h5>
										<h6><ol>
											<l>1. Created and maintained SQL database of about 1M records for seamless data retrieval.</l> </br>
											<l>2. Worked on a project to create a database for Resort Management System using the EER Model, Logical Model, Relational Model and storing the data to MySQL. Additionally, performed EDA and created dashboards using PowerBI.</l> 
										</ol>
										</h6>
										</div>
										</div>
										</div> 
									
									</li>
									
						
									
									

									<li class="style3">
										<span class="icon solid fa-chart-pie"></span>
										<br/>
										<div class="popup-link">
										<a href="#popup3">Data Visualization </br><strong>+</strong></a>
										<div id="popup3" class="popup-container">
										<div class="popup-content">
										<a href="#second" class="close">&times;</a>
										<h3>Data Visualization</h3>
										<h5>Tools: Tableau, PowerBI, Python (Seaborn, Matplotlib, Plotly), R (ggplot,plotly, RShiny, Flourish, Data Wrapper)</h5>
										<h6>1.  Designed 20+ dashboards leveraging Tableau to showcase KPI’s to executive management for decision-making. </br>
											2.  Analysed over 100k records and created a compelling dashboards using Tableau on World Tourism Overview. </br>
										    3.  Explored and analysed Ivy League schools data to gain insights on enrollment rate, rankings, retention rates using Rshiny, ggplot, Ploly, Flourish and Data Wrapper in a team of 3. <a href="https://sites.google.com/view/project-1group-29/what-are-the-ivy-leagues" style="color:blue;">Link</a></br>
										</h6>
										</div>
										</div>
										</div>  
									</li>
									<li class="style4">
										<span class="icon solid fa-laptop-code"></span>
										<br/>
										<div class="popup-link">
										<a href="#popup4">Machine Learning </br><strong>+</strong></a>
										<div id="popup4" class="popup-container">
										<div class="popup-content">
										<a href="#second" class="close">&times;</a>
										<h3>Machine Learning</h3>
										<h5>Tools: Python (sklearn, NLTK)</h5>
										<h6>1. Performed Sentiment Analysis on Hotel Review data by employing techniques such as text processing, feature extarcting and categorized data to identify whether the sentiment is positive, negative or neutral.</br> 
											2. Built a machine learning model from 790k data points, conducted various methods dealing with imbalanced classification problems and achieved 92% AUC-ROC by tuning hyperparameters using k-fold cross validation. </br>
											3. Customer Churn Prediction: Implemented various classification algorithms to predict whether a customer churns from service provider and an accuracy of 82% is obtained from Support Vector Machine.</br>
											4. Used K-means and Hierarchical Clustering methods to compare and group countries based on selected attributes from world indicators dataset.
										</h6>
										
										</div>
										</div>
										</div> 
									</li>
								</ul>

								<ul class="statistics">
									
									<li class="style1">
										<span class="icon solid fa-database"></span>
										<br/> 
										<div class="popup-link">
										<a href="#popup1">Data Warehousing</br><strong>+</strong></a>
										<div id="popup1" class="popup-container">
										<div class="popup-content">
										<a href="#second" class="close">&times;</a>
										<h3>Data Management</h3>
										<h5>Tools: Talend, Informatica, AWS Redshift, Snowflake</h5>
										<h6><ol>
											<l>1. Engineered and managed data ingestion pipelines to extract, transform and load (ETL) structured and unstructured data</l> </br>
											<l>2. Implemented data quality checks and data cleansing processes within ETL pipelines, reducing data errors and improving data accuracy</l> 
										</ol>
										</h6>
										</div>
										</div>
										</div> 
									
									</li>
									
						
									
									

									<li class="style3">
										<span class="icon solid fa-chart-pie"></span>
										<br/>
										<div class="popup-link">
										<a href="#popup3">Data Analysis </br><strong>+</strong></a>
										<div id="popup3" class="popup-container">
										<div class="popup-content">
										<a href="#second" class="close">&times;</a>
										<h3>Data Analysis</h3>
										<h5>Tools: SSRS, SQL Workbench, Jupyter Notebooks </h5>
										<h6>1.  Led data cleansing initiative and performed ad-hoc analysis on large-scale datasets to interpret trends, leveraging advanced SQL techniques and   automated python scripts to extract, clean, manipulate and analyze data, resulting in improved operational efficiency and cost reductions </br>
										    2.  Created numerous SQL queries over large datasets(>1M records) to carry out ad-hoc analysis for 4 departments to identify, analyze, and interpret trends and patterns in datasets and shared with stakeholders </br>
										    3.  Analyzed customer behavior and sales trends using SQL, Adobe Analytics and Google Analytics tools, prepared monthly reports, enhancing marketing and promotional programs for web application, improving customer experience and leading to 15% increase in digital sales <a href="https://sites.google.com/view/project-1group-29/what-are-the-ivy-leagues" style="color:blue;">Link</a></br>
										</h6>
										</div>
										</div>
										</div>  
									</li>
									<li class="style4">
										<span class="icon solid fa-laptop-code"></span>
										<br/>
										<div class="popup-link">
										<a href="#popup4"> Collaboration </br><strong>+</strong></a>
										<div id="popup4" class="popup-container">
										<div class="popup-content">
										<a href="#second" class="close">&times;</a>
										<h3>Collaboration</h3>
										<h5>Tools: Tableau, Power BI, JIRA, Confluence </h5>
										<h6>1. Collaborated with clients to gather business and user requirements, design and develop critical data systems infrastructures ensuring scalability </br> 
											2. Collaborated with sales and marketing teams to extract, synthesize and analyze data, define and validate key performance indicators and performance metrics and reporting requirements, define sales and growth strategies and drive business growth </br>
										</h6>
										
										</div>
										</div>
										</div> 
									</li></ul>
								<ul class="statistics">
		
		<li class="style1">
			<span class="icon solid fa-database"></span>
			<br/> 
			<div class="popup-link">
			<a href="#popup1">Business Intelligence & Reporting</br><strong>+</strong></a>
			<div id="popup1" class="popup-container">
			<div class="popup-content">
			<a href="#second" class="close">&times;</a>
			<h3>Business Intelligence</h3>
			<h5>Tools: ETL/ ELT, Talend, Tableau, Power BI </h5>
			<h6><ol>
				<l>1. Engineered and managed data ingestion pipelines to extract, transform and load (ETL) financial data exceeding 1TB from multiple sources, ensuring compliance with data standards for ML model training and business intelligence </l> </br>
				<l>2. Led the design and implementation of ETL project to extract, transform and load data from diverse energy sources into a data warehouse. Utilized Tableau and AWS Quick Sight for in-depth analysis of large datasets, enhancing data-driven decision-making</l> 
			</ol>
			</h6>
			</div>
			</div>
			</div> 
		
		</li>
		

		
		

		<li class="style3">
			<span class="icon solid fa-chart-pie"></span>
			<br/>
			<div class="popup-link">
			<a href="#popup3">Data Governance </br><strong>+</strong></a>
			<div id="popup3" class="popup-container">
			<div class="popup-content">
			<a href="#second" class="close">&times;</a>
			<h3>Data Governance</h3>
			<h5>Tools: Collibra, Alation, Data Cataloging, Data Dictionaries</h5>
			<h6>1.  Spearheaded development of 15+ data quality metrics and KPIs, creating comprehensive documentation of BI processes and standardized reporting frameworks, resulting in a 40% increase in data quality visibility for senior management</br>
				2.  Created and maintained detaile d data catalogs and data dictionaries for over 500 data elements, including definitions, data types and business context and standardizing data understanding across departments and reduced misinterpretation of data by 35% </br>
				3.  Collaborated with IT teams to resolve data discrepancies, achieving a 20% reduction in data errors by implementing data validation rules, enhancing data integrity and data accuracy, ensuring compliance with organizational data governance standards </br>
			</h6>
			</div>
			</div>
			</div>  
		</li>
		<li class="style4">
			<span class="icon solid fa-laptop-code"></span>
			<br/>
			<div class="popup-link">
			<a href="#popup4"> Data Quality & Analysis </br><strong>+</strong></a>
			<div id="popup4" class="popup-container">
			<div class="popup-content">
			<a href="#second" class="close">&times;</a>
			<h3>Data Quality Analysis </h3>
			<h5>Tools: SQL, Python Automation, JIRA</h5>
			<h6>1. Collaborated with data owners and consumers to develop a data quality dashboard, resulting in a 35% increase in data issue identification and improving data reliability across 5 key business domains for enhanced decision-making processes</br> 
				2. Collaborated with IT teams to resolve data discrepancies, achieving a 20% reduction in data errors by implementing data validation rules, enhancing data integrity and data accuracy, ensuring compliance with organizational data governance standards </br>
				3. Implemented data quality checks and data cleansing processes within ETL pipelines, reducing data errors by 35% and improving data accuracy, completeness, and consistency, leading to improved data reliability, ensuring quality for downstream analytics</br>
				4. Led data cleansing initiative and performed ad-hoc analysis on large-scale datasets to interpret trends, leveraging advanced SQL techniques and   automated python scripts to extract, clean, manipulate and analyze data, resulting in improved operational efficiency and cost reductions</br>
			</h6>
			
			</div>
			</div>
			</div> 
		</li>
						
									
									

									
									
								</ul>
									
									
							</section>
							

						<!-- Second Section -->
							<section id="projects" class="main special">
								<header class="major">
									<h2>Projects</h2>
								</header>
								<ul class="features">
									<li>
										<span class="icon solid major style2 fa-chart-line"></span>
										<a href="https://github.com/ChaithanyaSGudipati/AirbnbPrediction"><h3><u><strong>MLOps Pipeline for Airbnb Prediction</strong></u></h3></a>
										<p align="justify">The project is aimed to  forecast Airbnb price using predictive modelling and time-series analysis and built an end-to-end CI/CD pipeline on AWS Sagemaker...</p>
									</li>
									<li>
										<span class="icon solid major style3 fa-chart-line"></span>
										<a href="https://github.com/ChaithanyaSGudipati/yelprecommendationsystem"><h3><u><strong>Yelp Restaurant Recommendation System</strong></u></h3></a>
										<p align="justify">Leveraged Yelp reviews and ratings data to build recommendation system with 77% precision, exploring graph neural networks and optimized model performance by hyperparameter tuning...</p>
									</li>
									<li>
										<span class="icon solid major style1 fa-chart-line"></span>
										<a href="https://github.com/ChaithanyaSGudipati/SentimentAnalysis"><h3><u><strong>Sentiment Analysis</strong></u></h3></a>
										<p align="justify"> Performed Sentiment Analysis on hotel reviews data and classified the sentiment into positive, negative and neutral...</p>
									</li>
									
								</ul>
									<ul class="features">
										<li>
											<span class="icon solid major style3 fa-chart-line"></span>
											<a href="https://github.com/ChaithanyaSGudipati/boston_crime_prediction"><h3><u><strong>Boston Crime Prediction</strong></u></h3></a>
											<p>The aim of this project is to find factors like time and area affects the crime rate and count of crime given the factors.</p>
										</li>
										<li>
											<span class="icon solid major style1 fa-chart-line"></span>
											<a href="https://github.com/ChaithanyaSGudipati/TwitterDataAnalysis"><h3><u><strong>Twitter Data Analysis</strong></u></h3></a>
											<p>The Objective is to perform keyword network analysis and frequency analysis on tweets by Elon Musk for the years 2017-2022.</p>
										</li>
										<li>
											<span class="icon solid major style2 fa-credit-card"></span>
											<a href="https://github.com/ChaithanyaSGudipati/CreditDefaultprediction"><h3><u><strong>Credit Card Default Prediction</strong></u></h3></a>
											<p>The project is aimed at predicting the customers who are likely to default and help banks to prevent encountering the loss.</p>
										</li>
										
									</ul>
									<footer class="major">
										<ul class="actions special">
											<li><a href="https://github.com/ChaithanyaSGudipati" class="button">Learn More</a></li>
										</ul>
								</footer>
							</section>
							

						
						

					</div>

				<!-- Footer -->
					<footer id="footer">
						
						<section>
							<h2>Contact</h2>
							<dl class="alt">
								<dt>Phone</dt>
								<dd>(469)-370-9767</dd>
								<dt>Email</dt>
								<dd><a href="#">chaithanya.gd1606@gmail.com</a></dd>
								<dt>Address</dt>
							
							</dl>
							<ul class="icons">
								
								<li><a href="https://github.com/ChaithanyaSGudipati" class="icon brands fa-github alt"><span class="label">Facebook</span></a></li>
								<li><a href="https://www.linkedin.com/in/chaithanya-s-gudipati-b16370167/" class="icon brands fa-linkedin alt"><span class="label">GitHub</span></a></li>
								<li><a href="https://public.tableau.com/app/profile/chaithanya.sudha.gudipati" class="icon brands brands fa-tumblr alt"><span class="label">Tableau</span></a></li>
								<li><a href="https://sites.google.com/view/project-1group-29/home" class="icon brands brands fa-chrome alt"><span class="label">Work Sample</span></a></li>
							</ul>
						</section>
						<p class="copyright">&copy; 2022 Chaithanya G</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
<script>
// When the user clicks on div, open the popup
function myFunction() {
  var popup = document.getElementById("myPopup");
  popup.classList.toggle("show");
}
</script>
	</body>
</html>
